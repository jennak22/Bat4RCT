{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9SoFLIx-rF-N"
   },
   "source": [
    "# Text Classification Using Heuristic Approach with Keyword Matching\n",
    "\n",
    "This code is to use a keyword match method on RCT (Randomized Controlled Trial) data for classification \n",
    "\n",
    "Author: Jenna Kim  \n",
    "Created: 2022/2/20  \n",
    "Last Modified: 2022/9/29  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Update:  \n",
    "- Modify load_data funtion to read in txt file: V2  \n",
    "- Add code to remove duplicates: V2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KjDQGl91wA78"
   },
   "source": [
    "# 1. Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iCQmTfQRrF-S"
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "acU18CBUv4xQ"
   },
   "outputs": [],
   "source": [
    "# Hide warning messages from display\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# disply all the dataframe columns\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EmfKPvo9wEne"
   },
   "source": [
    "# 2. Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_txt(filename, colname, record):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read in input file and load data\n",
    "    \n",
    "    filename: csv file\n",
    "    record: text file to save summary\n",
    "\n",
    "    return: dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    ## 1. Read in data from input file\n",
    "    df = pd.read_csv(filename, sep=\"\\t\", encoding='utf-8', header=None, names=['pmid', 'pubtype', 'year', 'title', 'abstract'])\n",
    "    \n",
    "    # No of rows and columns\n",
    "    print(\"No of Rows (Raw data): {}\".format(df.shape[0]), file=record)\n",
    "    print(\"No of Columns: {}\".format(df.shape[1]), file=record)\n",
    "    print(\"No of Rows (Raw data): {}\".format(df.shape[0]))\n",
    "    print(\"No of Columns: {}\".format(df.shape[1]))\n",
    "    \n",
    "    ## 2. Select data needed for processing & convert labels\n",
    "    df = df[['pmid', 'title', 'abstract', 'pubtype']]\n",
    "    \n",
    "    ## 3. Cleaning data \n",
    "    #Trim unnecessary spaces for strings\n",
    "    df[\"title\"] = df[\"title\"].apply(lambda x: x.strip())\n",
    "    df[\"abstract\"] = df[\"abstract\"].apply(lambda x: x.strip())\n",
    "\n",
    "    # Remove null values \n",
    "    df=df.dropna()\n",
    "\n",
    "    print(\"No of rows (After dropping null): {}\".format(df.shape[0]), file=record)\n",
    "    print(\"No of columns: {}\".format(df.shape[1]), file=record)\n",
    "    print(\"No of rows (After dropping null): {}\".format(df.shape[0]))\n",
    "    print(\"No of columns: {}\".format(df.shape[1]))\n",
    "\n",
    "    # Remove duplicates and keep first occurrence\n",
    "    df.drop_duplicates(subset=['pmid'], keep='first', inplace=True)\n",
    "\n",
    "    print(\"No of rows (After removing duplicates): {}\".format(df.shape[0]), file=record)\n",
    "    print(\"No of rows (After removing duplicates): {}\".format(df.shape[0]))\n",
    "        \n",
    "    ## 4. Select text columns\n",
    "    if colname == \"title\":\n",
    "        df = df[['pmid', 'title', 'pubtype']]\n",
    "        df.rename({\"title\": \"sentence\", \"pubtype\": \"label\"}, axis=1, inplace=True)\n",
    "    elif colname == \"abs\":\n",
    "        df = df[['pmid', 'abstract', 'pubtype']]\n",
    "        df.rename({\"abstract\": \"sentence\", \"pubtype\": \"label\"}, axis=1, inplace=True)\n",
    "    elif colname == \"mix\":\n",
    "        df['mix'] = df[['title','abstract']].apply(lambda x : '{} {}'.format(x[0],x[1]), axis=1)\n",
    "        df = df[['pmid', 'mix', 'pubtype']]\n",
    "        df.rename({\"mix\": \"sentence\", \"pubtype\": \"label\"}, axis=1, inplace=True)\n",
    "\n",
    "    # Check the first few instances\n",
    "    print(\"\\n<Data View: First Few Instances>\", file=record)\n",
    "    print(\"\\n\", df.head(), file=record)\n",
    "    print(\"\\n<Data View: First Few Instances>\")\n",
    "    print(\"\\n\", df.head())\n",
    "    \n",
    "    # No of lables and rows \n",
    "    print('\\nClass Counts(label, row): Total', file=record)\n",
    "    print(df.label.value_counts(), file=record)   \n",
    "    print('\\nClass Counts(label, row): Total')\n",
    "    print(df.label.value_counts())\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "UiYSV0gaEoYF"
   },
   "outputs": [],
   "source": [
    "def load_data(filename, colname, record):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read in input file and load data\n",
    "    \n",
    "    filename: csv file\n",
    "    colname: column name used for text input data\n",
    "    record: text file to save summary\n",
    "\n",
    "    return: dataframe\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(filename, encoding='utf-8')\n",
    "    \n",
    "    # No of rows and columns\n",
    "    print(\"No of Rows (Raw data): {}\".format(df.shape[0]), file=record)\n",
    "    print(\"No of Columns: {}\".format(df.shape[1]), file=record)\n",
    "    \n",
    "    print(\"No of Rows (Raw data): {}\".format(df.shape[0]))\n",
    "    print(\"No of Columns: {}\".format(df.shape[1]))\n",
    "    \n",
    "    # Select data needed for processing & convert labels\n",
    "    df = df[['pmid', 'title', 'abstract', 'pubtype']]\n",
    "    df.iloc[:, -1] = df.iloc[:, -1].map({'RCT':1, 'Other':0})\n",
    "    \n",
    "    # Remove null values \n",
    "    df=df.dropna()\n",
    "\n",
    "    print(\"No of rows (After removing null): {}\".format(df.shape[0]), file=record)\n",
    "    print(\"No of columns: {}\".format(df.shape[1]), file=record)\n",
    "    \n",
    "    print(\"No of rows (After removing null): {}\".format(df.shape[0]))\n",
    "    print(\"No of columns: {}\".format(df.shape[1]))\n",
    "        \n",
    "    # Select text columns\n",
    "    if colname == \"title\":\n",
    "        df = df[['pmid', 'title', 'pubtype']]\n",
    "        df.rename({\"title\": \"sentence\", \"pubtype\": \"label\"}, axis=1, inplace=True)\n",
    "    elif colname == \"abs\":\n",
    "        df = df[['pmid', 'abstract', 'pubtype']]\n",
    "        df.rename({\"abstract\": \"sentence\", \"pubtype\": \"label\"}, axis=1, inplace=True)\n",
    "    elif colname == \"mix\":\n",
    "        df['mix'] = df[['title','abstract']].apply(lambda x : '{} {}'.format(x[0],x[1]), axis=1)\n",
    "        df = df[['pmid', 'mix', 'pubtype']]\n",
    "        df.rename({\"mix\": \"sentence\", \"pubtype\": \"label\"}, axis=1, inplace=True)\n",
    "\n",
    "    # Check the first few instances\n",
    "    print(\"\\n<Data View: First Few Instances>\", file=record)\n",
    "    print(\"\\n\", df.head(), file=record)\n",
    "    print(\"\\n<Data View: First Few Instances>\")\n",
    "    print(\"\\n\", df.head())\n",
    "    \n",
    "    # No of lables and rows \n",
    "    print('\\nClass Counts(label, row): Total', file=record)\n",
    "    print(df.label.value_counts(), file=record)\n",
    "    \n",
    "    print('\\nClass Counts(label, row): Total')\n",
    "    print(df.label.value_counts())\n",
    "     \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "b0GRsjv3_40h"
   },
   "outputs": [],
   "source": [
    "def find_exact_match(string, keywords):\n",
    "  \"\"\"\n",
    "    Search exact match of terms in a text\n",
    "    \n",
    "    string: text string\n",
    "    keywords: a list of terms used as keyword\n",
    "\n",
    "    return: a list of matched terms\n",
    "    \n",
    "  \"\"\"\n",
    "  \n",
    "  items = []\n",
    "  for keyword in keywords:\n",
    "    term = r'\\b' + keyword + r'\\b'\n",
    "    found = re.findall(term, string, flags=re.IGNORECASE)\n",
    "\n",
    "    if len(found) > 0:\n",
    "      [items.append(word) for word in found]\n",
    "\n",
    "  return items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Jno64EHKulFf"
   },
   "outputs": [],
   "source": [
    "def convert_match_to_label(df_data, keywords):\n",
    "  \n",
    "  \"\"\"\n",
    "    Identify strings that match keywords in texts \n",
    "    and convert to label if an instance includes any matched term\n",
    "    \n",
    "    df_data: input dataframe\n",
    "    keywords: a list of terms used as keyword\n",
    "\n",
    "    return: dataframe that includes matched terms and converted labels\n",
    "    \n",
    "  \"\"\"\n",
    "  \n",
    "  # 1. Remove punctuation from texts\n",
    "  df_data[\"sent_process\"] = df_data[\"sentence\"].str.replace('[!?,]', '')\n",
    "\n",
    "  # 2. Detect keyword terms in each text\n",
    "  df_data[\"match\"] = df_data[\"sent_process\"].apply(lambda x: find_exact_match(x, keywords))\n",
    "  \n",
    "  \n",
    "  # 3. Label each match\n",
    "  df_data[\"pred\"] = df_data[\"match\"].apply(lambda x: 1 if len(x)>0 else 0)\n",
    "\n",
    "  return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ctZ80-2prF-Y"
   },
   "outputs": [],
   "source": [
    "def evaluate_model(y_test, y_pred, record, eval_model=0):\n",
    "    \"\"\"\n",
    "      evaluate model performance\n",
    "      \n",
    "      y_test: y test data\n",
    "      y_pred: t prediction score\n",
    "      record: text file to save output\n",
    "      eval_model: indicator if this funtion is on or off\n",
    "      \n",
    "    \"\"\"\n",
    "    \n",
    "    if eval_model:\n",
    "        \n",
    "        print('\\nConfusion Matrix:\\n', file=record)\n",
    "        print('\\nConfusion Matrix:\\n')\n",
    "        print(confusion_matrix(y_test, y_pred), file=record)\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        \n",
    "        print('\\nClassification Report:\\n', file=record)\n",
    "        print('\\nClassification Report:\\n')\n",
    "        print(classification_report(y_test, y_pred, digits=4), file=record)\n",
    "        print(classification_report(y_test, y_pred, digits=4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtuA57AQwTjA"
   },
   "source": [
    "# 3. Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5YROMNEZrF-Z"
   },
   "outputs": [],
   "source": [
    "def main(input_file, \n",
    "         colname, \n",
    "         keywords,   \n",
    "         eval_on, \n",
    "         match_file,\n",
    "         result_file):\n",
    "    \n",
    "    \"\"\"\n",
    "       Main function for processing data, model fitting, and prediction\n",
    "       \n",
    "       input_file: input file\n",
    "       colname: colume name for selection between title and abstract\n",
    "       keywords: a list of terms used for keyword matching\n",
    "       eval_on: indicator of model evaluation on or off\n",
    "       match_file: name of csv file to save output\n",
    "       result_file: name of text file to save evaluation\n",
    "       \n",
    "    \"\"\"\n",
    "    \n",
    "    ## 0. open result file for records\n",
    "    f=open(result_file, \"a\")\n",
    "    \n",
    "    # Check processing time\n",
    "    proc_start_time = timeit.default_timer()\n",
    "    \n",
    "    ## 1. Load data\n",
    "    \n",
    "    print(\"\\n************** Loading Data **************\\n\", file=f)\n",
    "    print(\"\\n************** Loading Data **************\\n\")\n",
    "    #df = load_data(input_file, colname, record=f)       # for comma delimited csv file\n",
    "    df = load_data_txt(input_file, colname, record=f)    # for tab delimited txt file\n",
    "    \n",
    "    # testing\n",
    "    print(\"\\n<First Sentence>\\n{}\".format(df.sentence[0]), file=f)\n",
    "    print(\"\\n<First Sentence>\\n{}\".format(df.sentence[0]))\n",
    "\n",
    "    ## 2. Train and test split\n",
    "    \n",
    "    print(\"\\n************** Spliting Data **************\\n\", file=f)\n",
    "    print(\"\\n************** Spliting Data **************\\n\")\n",
    "    \n",
    "    df_train, df_test = train_test_split(df, test_size=0.2, random_state=42, stratify=df.label)\n",
    "    df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=42, stratify=df_test.label)\n",
    "    \n",
    "    #for testing only: small size data\n",
    "    #df_train, df_test = train_test_split(df, test_size=0.99, random_state=42, stratify=df.label)\n",
    "    #df_val, df_test = train_test_split(df_test, test_size=0.99, random_state=42, stratify=df_test.label)\n",
    "    #df_notuse, df_test = train_test_split(df_test, test_size=0.01, random_state=42, stratify=df_test.label)\n",
    "    \n",
    "    print(\"Train Data: {}\".format(df_train.shape), file=f)\n",
    "    print(\"Val Data: {}\".format(df_val.shape), file=f)\n",
    "    print(\"Test Data: {}\".format(df_test.shape), file=f)   \n",
    "    print(\"Train Data: {}\".format(df_train.shape))\n",
    "    print(\"Val Data: {}\".format(df_val.shape))\n",
    "    print(\"Test Data: {}\".format(df_test.shape))\n",
    "    \n",
    "    print('\\nClass Counts(label, row): Train', file=f)\n",
    "    print(df_train.label.value_counts(), file=f)\n",
    "    print('\\nClass Counts(label, row): Val', file=f)\n",
    "    print(df_val.label.value_counts(), file=f)\n",
    "    print('\\nClass Counts(label, row): Test', file=f)\n",
    "    print(df_test.label.value_counts(), file=f)\n",
    "    \n",
    "    print(\"\\nTest Data: First Few Instances\", file=f)\n",
    "    print(df_test.head(), file=f)\n",
    "    print(\"\\nTest Data: First Few Instances\")\n",
    "    print(df_test.head())\n",
    "    \n",
    "    # Reset index\n",
    "    df_train=df_train.reset_index(drop=True)\n",
    "    df_val=df_val.reset_index(drop=True)\n",
    "    df_test=df_test.reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\n************** Processing Data **************\", file=f)\n",
    "    print(\"\\n************** Processing Data **************\")\n",
    "\n",
    "    print(\"Test Data: {}\".format(df_test.shape), file=f)\n",
    "    print(\"Test Data: {}\".format(df_test.shape))\n",
    "    print('\\nClass Counts(label, row): Test', file=f)\n",
    "    print(df_test.label.value_counts(), file=f)\n",
    "    print(\"\\nTest Data: First Few Instances\", file=f)\n",
    "    print(df_test.head(), file=f)\n",
    "    print(\"\\nTest Data: First Few Instances\")\n",
    "    print(df_test.head())\n",
    "    \n",
    "    ## 3. Heuristic Method: keyword matching\n",
    "\n",
    "    print(\"\\n************** Heuristic Method: Keyword Match **************\", file=f)\n",
    "    print(\"\\n************** Heuristic Method: Keyword Match **************\")\n",
    "    \n",
    "    #df_matched=convert_match_to_label(df_train, keywords)   # for testing only: use df_test for implementation\n",
    "    df_matched=convert_match_to_label(df_test, keywords)   \n",
    "    \n",
    "    print(\"Output Data: {}\".format(df_matched.shape), file=f)\n",
    "    print(\"\\nOutput Data: {}\".format(df_matched.shape))\n",
    "    \n",
    "    print(\"\\nOutput Data: First Few Instances\", file=f)\n",
    "    print(df_matched.head(), file=f) \n",
    "    print(\"\\nOutput Data: First Few Instances\")\n",
    "    print(df_matched.head()) \n",
    "\n",
    "    ## Save output\n",
    "    df_matched.to_csv(match_file, encoding='utf-8', index=False, header=True)\n",
    "\n",
    "    ## 4. Evaluating performance      \n",
    "    print(\"\\n************** Evaluating performance **************\", file=f)\n",
    "    print(\"\\n************** Evaluating performance **************\")\n",
    "\n",
    "    y_test = df_matched[\"label\"]\n",
    "    y_pred = df_matched[\"pred\"]\n",
    "\n",
    "    evaluate_model(y_test, y_pred, record=f, eval_model=eval_on)\n",
    "    \n",
    "    print(\"\\nOutput file:'\" + result_file + \"' Created\", file=f)\n",
    "    print(\"\\nOutput file:'\" + result_file + \"' Created\")\n",
    "    \n",
    "    proc_elapsed = timeit.default_timer() - proc_start_time\n",
    "    print(\"\\nTotal Processing Time: {}min\\n\".format(round(proc_elapsed/60)), file=f)\n",
    "    print(\"\\nTotal Processing Time: {}min\\n\".format(round(proc_elapsed/60)))\n",
    "    \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYwmardMwKPF"
   },
   "source": [
    "# 4. Run code for implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pYt_qbIcrF-a",
    "outputId": "95b5b142-b754-411b-b5d3-04afb54b0ef1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "************** Loading Data **************\n",
      "\n",
      "No of Rows (Raw data): 500068\n",
      "No of Columns: 5\n",
      "No of rows (After dropping null): 500068\n",
      "No of columns: 4\n",
      "No of rows (After removing duplicates): 499963\n",
      "\n",
      "<Data View: First Few Instances>\n",
      "\n",
      "        pmid                                           sentence  label\n",
      "0  18439781  Two patients subdued with a TASER® device: cas...      0\n",
      "1  18468833  A case of Takayasu arteritis causing subclavia...      0\n",
      "2  18481181  Pathophysiology of hypopituitarism in the sett...      0\n",
      "3  18728056  The cardiovascular risk factor, soluble CD40 l...      1\n",
      "4  18790590  Horner syndrome due to carotid dissection. [BA...      0\n",
      "\n",
      "Class Counts(label, row): Total\n",
      "0    399977\n",
      "1     99986\n",
      "Name: label, dtype: int64\n",
      "\n",
      "<First Sentence>\n",
      "Two patients subdued with a TASER® device: cases and review of complications. In the United States, an increasing number of law enforcement agencies have employed the use of TASER® (TASER International Inc., Scottsdale, AZ) devices to temporarily immobilize violent subjects. There are reports in the lay press of adverse outcomes occurring in patients on whom TASER® devices have been deployed. Rhabdomyolysis has been associated with patients sustaining a TASER® shock, with a 1% incidence rate in subjects subdued with earlier versions of the device and then brought to the Emergency Department (ED). We present the cases of 2 patients who were seen in our ED after exhibiting violent behavior and receiving TASER® shocks. Both were hospitalized and received treatment for mild rhabdomyolysis. Both patients had multiple other characteristics that have been found to have an association with the development of rhabdomyolysis, in addition to the shocks they received. A review and discussion of the available medical literature on the subject follows, describing several complications that have been documented in patients after receiving TASER® shocks. Although a direct link between the TASER® and the reported adverse effects has not been established, patients who undergo restraint via this device frequently have pre-existing conditions or have exhibited behavior that places them at risk for the development of those effects. Such awareness of these possible complications is vital because the evaluation and management of patients developing adverse effects after these events will commonly occur in the ED.\n",
      "\n",
      "************** Spliting Data **************\n",
      "\n",
      "Train Data: (399970, 3)\n",
      "Val Data: (49996, 3)\n",
      "Test Data: (49997, 3)\n",
      "\n",
      "Test Data: First Few Instances\n",
      "            pmid                                           sentence  label\n",
      "141906  24081098  Resolving spatial modes of lasers via matrix c...      0\n",
      "5372    21075537  A comparative analysis of cetirizine, gabapent...      1\n",
      "251994  26642726  [A Clinical Case of Grief Hallucination throug...      0\n",
      "10967   21255258  Clinical indicators of ineffective breathing p...      0\n",
      "266669  26996521  Cryogenic processes and fire activity in a hig...      0\n",
      "\n",
      "************** Processing Data **************\n",
      "Test Data: (49997, 3)\n",
      "\n",
      "Test Data: First Few Instances\n",
      "       pmid                                           sentence  label\n",
      "0  24081098  Resolving spatial modes of lasers via matrix c...      0\n",
      "1  21075537  A comparative analysis of cetirizine, gabapent...      1\n",
      "2  26642726  [A Clinical Case of Grief Hallucination throug...      0\n",
      "3  21255258  Clinical indicators of ineffective breathing p...      0\n",
      "4  26996521  Cryogenic processes and fire activity in a hig...      0\n",
      "\n",
      "************** Heuristic Method: Keyword Match **************\n",
      "\n",
      "Output Data: (49997, 6)\n",
      "\n",
      "Output Data: First Few Instances\n",
      "       pmid                                           sentence  label  \\\n",
      "0  24081098  Resolving spatial modes of lasers via matrix c...      0   \n",
      "1  21075537  A comparative analysis of cetirizine, gabapent...      1   \n",
      "2  26642726  [A Clinical Case of Grief Hallucination throug...      0   \n",
      "3  21255258  Clinical indicators of ineffective breathing p...      0   \n",
      "4  26996521  Cryogenic processes and fire activity in a hig...      0   \n",
      "\n",
      "                                        sent_process  \\\n",
      "0  Resolving spatial modes of lasers via matrix c...   \n",
      "1  A comparative analysis of cetirizine gabapenti...   \n",
      "2  [A Clinical Case of Grief Hallucination throug...   \n",
      "3  Clinical indicators of ineffective breathing p...   \n",
      "4  Cryogenic processes and fire activity in a hig...   \n",
      "\n",
      "                             match  pred  \n",
      "0                               []     0  \n",
      "1  [randomized trials, randomized]     1  \n",
      "2                               []     0  \n",
      "3                               []     0  \n",
      "4                               []     0  \n",
      "\n",
      "************** Evaluating performance **************\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[38574  1424]\n",
      " [ 2686  7313]]\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9349    0.9644    0.9494     39998\n",
      "           1     0.8370    0.7314    0.7806      9999\n",
      "\n",
      "    accuracy                         0.9178     49997\n",
      "   macro avg     0.8860    0.8479    0.8650     49997\n",
      "weighted avg     0.9153    0.9178    0.9157     49997\n",
      "\n",
      "\n",
      "Output file:'eval_baseline_heuristic_mix.txt' Created\n",
      "\n",
      "Total Processing Time: 1min\n",
      "\n",
      "\n",
      "************** Processing Completed **************\n",
      "\n",
      "CPU times: user 1min 8s, sys: 972 ms, total: 1min 9s\n",
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if __name__== \"__main__\":\n",
    "    \n",
    "    ###### 1. Set Parameter Values ######\n",
    "    \n",
    "    #### 1-1. Input file name & which column\n",
    "    input_filename=\"output_rct.txt\"  \n",
    "    column_name = \"mix\"                                        # 'title' for title text; 'abs' for abstract; 'mix' for title + abstract\n",
    "    \n",
    "    #### 1-2. Evaluation applied?    \n",
    "    eval_on=1                                                  # 0 for no; 1 for yes (confusion matrix/classification report)\n",
    "    \n",
    "    #### 1-3. Term list for keyword matching\n",
    "    keyword_list = ['RCT', 'RCTs', \n",
    "                    'randomized controlled trial', 'randomized controlled trials', 'randomised controlled trial', 'randomised controlled trials', \n",
    "                    'randomized trial', 'randomized trials', 'randomised trial', 'randomised trials',\n",
    "                    'randomized clinical trial', 'randomized clinical trials', 'randomised clinical trial', 'randomised clinical trials',\n",
    "                    'randomized controlled', 'randomised controlled', 'radomized clinical', 'randomised clinical',\n",
    "                    'randomized', 'randomised', 'clinical trial', 'clinical trials', 'controlled trial', 'controlled trials']\n",
    "    \n",
    "    ###### 2. Run Main Fuction ###### \n",
    "    output_file = \"result_baseline_heuristic_\" + column_name + \".csv\" \n",
    "    eval_file = \"eval_baseline_heuristic_\" + column_name + \".txt\" \n",
    "            \n",
    "    main(input_file=input_filename, \n",
    "         colname=column_name,\n",
    "         keywords=keyword_list,\n",
    "         eval_on=eval_on,\n",
    "         match_file=output_file,\n",
    "         result_file=eval_file\n",
    "         )\n",
    "        \n",
    "    print(\"\\n************** Processing Completed **************\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QftyM5zKrF-b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "RCT_Heuristic.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_latest_p36",
   "language": "python",
   "name": "conda_pytorch_latest_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
